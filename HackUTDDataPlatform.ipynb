{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HackUTDDataPlatform.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoKAuKc99LYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2adf19f2-972d-434e-de55-5017ac84b03a"
      },
      "source": [
        "%cd drive/MyDrive/HackUTDProject/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/HackUTDProject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k87Le4Yb971K",
        "outputId": "14f35097-5d5f-404d-fc18-69ca5be62d28"
      },
      "source": [
        "!pip install twelvedata[pandas,matplotlib,plotly,websocket-client]\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting twelvedata[matplotlib,pandas,plotly,websocket-client]\n",
            "  Downloading twelvedata-1.2.3-py2.py3-none-any.whl (44 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▍                        | 10 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 20 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 30 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 40 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 44 kB 1.4 MB/s \n",
            "\u001b[33mWARNING: twelvedata 1.2.3 does not provide the extra 'websocket-client'\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.22 in /usr/local/lib/python3.7/dist-packages (from twelvedata[matplotlib,pandas,plotly,websocket-client]) (2.23.0)\n",
            "Collecting pytimeparse<2,>=1.1\n",
            "  Downloading pytimeparse-1.1.8-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from twelvedata[matplotlib,pandas,plotly,websocket-client]) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from twelvedata[matplotlib,pandas,plotly,websocket-client]) (1.1.5)\n",
            "Requirement already satisfied: plotly>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from twelvedata[matplotlib,pandas,plotly,websocket-client]) (4.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->twelvedata[matplotlib,pandas,plotly,websocket-client]) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->twelvedata[matplotlib,pandas,plotly,websocket-client]) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->twelvedata[matplotlib,pandas,plotly,websocket-client]) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->twelvedata[matplotlib,pandas,plotly,websocket-client]) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->twelvedata[matplotlib,pandas,plotly,websocket-client]) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->twelvedata[matplotlib,pandas,plotly,websocket-client]) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.2.1->twelvedata[matplotlib,pandas,plotly,websocket-client]) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.2.1->twelvedata[matplotlib,pandas,plotly,websocket-client]) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22->twelvedata[matplotlib,pandas,plotly,websocket-client]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22->twelvedata[matplotlib,pandas,plotly,websocket-client]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22->twelvedata[matplotlib,pandas,plotly,websocket-client]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.22->twelvedata[matplotlib,pandas,plotly,websocket-client]) (2021.10.8)\n",
            "Installing collected packages: pytimeparse, twelvedata\n",
            "Successfully installed pytimeparse-1.1.8 twelvedata-1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbQSLIsf_TxU"
      },
      "source": [
        "\n",
        "table=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
        "df = table[0]\n",
        "df.to_csv('S&P500-Info.csv')\n",
        "df.to_csv(\"S&P500-Symbols.csv\", columns=['Symbol'])\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkDCBkcJ_tdX",
        "outputId": "6762637c-e4c4-44c6-af6f-bb0633cf2a81"
      },
      "source": [
        "import pandas as pd\n",
        "from twelvedata import TDClient\n",
        "import time\n",
        "def get_usdata(symbol_name, interval_time, data_points,keynum):\n",
        "    apikey1 = \"9369e3dfc0e94eac916f5dd74d0fcadb\"\n",
        "    apikey2 = \"2e16a63f1cc74165bb76b539d9714bf0\"\n",
        "    apikey3 = \"9af0a3239ffd46e5be312d0944c45f70\"\n",
        "    apikey4 = \"6ce628b88c56419d8e476125b0d164d1\"\n",
        "    apikey5 = \"061d6abefa0043adaf2e7c9546065aad\"\n",
        "    apikey6 = \"23042f079cd54ae48a2ebae53aeb8142\"\n",
        "    if keynum == 1:\n",
        "        apikeyput = apikey1\n",
        "    elif keynum == 2:\n",
        "        apikeyput = apikey2\n",
        "    elif keynum == 3:\n",
        "        apikeyput = apikey3\n",
        "    elif keynum == 4:\n",
        "        apikeyput = apikey4\n",
        "    elif keynum == 5:\n",
        "        apikeyput = apikey5\n",
        "    else:\n",
        "        apikeyput = apikey6\n",
        "\n",
        "    td = TDClient(apikey=apikeyput)\n",
        "    # Construct the necessary time serie\n",
        "    ts = td.time_series(\n",
        "        symbol=symbol_name,\n",
        "        interval=interval_time,\n",
        "        outputsize=data_points\n",
        "        )\n",
        "\n",
        "    # Returns pandas.DataFrame\n",
        "    data = ts.as_pandas()\n",
        "    #data = data.sort_index(axis=1, ascending=True)\n",
        "    data = data['close']\n",
        "    data = data.iloc[::-1]\n",
        "    \n",
        "    #data.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    #print(data)\n",
        "    return data\n",
        "  \n",
        "def main_pull(csvfile):\n",
        "  starttime=time.time()\n",
        "  data = pd.read_csv(csvfile)\n",
        "  key = 1\n",
        "  for index,row in data.iterrows():\n",
        "    try:\n",
        "      if((index+1)%12==0 and key<5):\n",
        "          key=key+1\n",
        "          df = get_usdata(row['Symbol'],'1day',365,key)\n",
        "          df.to_csv(row['Symbol']+'.csv')\n",
        "      elif((index+1)%12==0 and key>=5):\n",
        "          time.sleep(90.0 - ((time.time() - starttime) % 60.0))\n",
        "          key = 1\n",
        "          starttime = time.time()\n",
        "          df = get_usdata(row['Symbol'],'1day',365,key)\n",
        "          df.to_csv(row['Symbol']+'.csv')\n",
        "      else:\n",
        "          df = get_usdata(row['Symbol'],'1day',365,key)\n",
        "          df.to_csv(row['Symbol']+'.csv')\n",
        "    except:\n",
        "      print (\"No out\")\n",
        "  \n",
        "\n",
        "main_pull('S&P500-Info.csv')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYzT9Oa1ttkL"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('S&P500-Info.csv')\n",
        "li = []\n",
        "for index,row in df.iterrows():\n",
        "  try:\n",
        "    data = pd.read_csv(row['Symbol']+'.csv')\n",
        "    annual = 100*(data.loc[data.index[-1], 'close']-data['close'][0])/data['close'][0]\n",
        "    li.append(annual)\n",
        "  except:\n",
        "    li.append(-1)\n",
        "df['Annual Return'] = li\n",
        "df.to_csv('Symbols-info-annual.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFyIY48lrrmg"
      },
      "source": [
        "import re\n",
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "from textblob import TextBlob\n",
        "\n",
        "class TwitterClient(object):\n",
        "\t'''\n",
        "\tGeneric Twitter Class for sentiment analysis.\n",
        "\t'''\n",
        "\tdef __init__(self):\n",
        "\t\t'''\n",
        "\t\tClass constructor or initialization method.\n",
        "\t\t'''\n",
        "\t\t# keys and tokens from the Twitter Dev Console\n",
        "\t\tconsumer_key = ''\n",
        "\t\tconsumer_secret = ''\n",
        "\t\taccess_token = ''\n",
        "\t\taccess_token_secret = ''\n",
        "\n",
        "\t\t# attempt authentication\n",
        "\t\ttry:\n",
        "\t\t\t# create OAuthHandler object\n",
        "\t\t\tself.auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "\t\t\t# set access token and secret\n",
        "\t\t\tself.auth.set_access_token(access_token, access_token_secret)\n",
        "\t\t\t# create tweepy API object to fetch tweets\n",
        "\t\t\tself.api = tweepy.API(self.auth)\n",
        "\t\texcept:\n",
        "\t\t\tprint(\"Error: Authentication Failed\")\n",
        "\n",
        "\tdef clean_tweet(self, tweet):\n",
        "\t\t'''\n",
        "\t\tUtility function to clean tweet text by removing links, special characters\n",
        "\t\tusing simple regex statements.\n",
        "\t\t'''\n",
        "\t\treturn ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])\n",
        "\t\t\t\t\t\t\t\t\t|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "\n",
        "\tdef get_tweet_sentiment(self, tweet):\n",
        "\t\t'''\n",
        "\t\tUtility function to classify sentiment of passed tweet\n",
        "\t\tusing textblob's sentiment method\n",
        "\t\t'''\n",
        "\t\t# create TextBlob object of passed tweet text\n",
        "\t\tanalysis = TextBlob(self.clean_tweet(tweet))\n",
        "\t\t# set sentiment\n",
        "\t\tif analysis.sentiment.polarity > 0:\n",
        "\t\t\treturn 'positive'\n",
        "\t\telif analysis.sentiment.polarity == 0:\n",
        "\t\t\treturn 'neutral'\n",
        "\t\telse:\n",
        "\t\t\treturn 'negative'\n",
        "\n",
        "\tdef get_tweets(self, query, count = 10):\n",
        "\t\t'''\n",
        "\t\tMain function to fetch tweets and parse them.\n",
        "\t\t'''\n",
        "\t\t# empty list to store parsed tweets\n",
        "\t\ttweets = []\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\t# call twitter api to fetch tweets\n",
        "\t\t\tfetched_tweets = self.api.search(q = query, count = count)\n",
        "\n",
        "\t\t\t# parsing tweets one by one\n",
        "\t\t\tfor tweet in fetched_tweets:\n",
        "\t\t\t\t# empty dictionary to store required params of a tweet\n",
        "\t\t\t\tparsed_tweet = {}\n",
        "\n",
        "\t\t\t\t# saving text of tweet\n",
        "\t\t\t\tparsed_tweet['text'] = tweet.text\n",
        "\t\t\t\t# saving sentiment of tweet\n",
        "\t\t\t\tparsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
        "\n",
        "\t\t\t\t# appending parsed tweet to tweets list\n",
        "\t\t\t\tif tweet.retweet_count > 0:\n",
        "\t\t\t\t\t# if tweet has retweets, ensure that it is appended only once\n",
        "\t\t\t\t\tif parsed_tweet not in tweets:\n",
        "\t\t\t\t\t\ttweets.append(parsed_tweet)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\ttweets.append(parsed_tweet)\n",
        "\n",
        "\t\t\t# return parsed tweets\n",
        "\t\t\treturn tweets\n",
        "\n",
        "\t\texcept tweepy.TweepError as e:\n",
        "\t\t\t# print error (if any)\n",
        "\t\t\tprint(\"Error : \" + str(e))\n",
        "\n",
        "def main():\n",
        "\t# creating object of TwitterClient Class\n",
        "\tapi = TwitterClient()\n",
        "\t# calling function to get tweets\n",
        "\ttweets = api.get_tweets(query = 'Donald Trump', count = 200)\n",
        "\n",
        "\t# picking positive tweets from tweets\n",
        "\tptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
        "\t# percentage of positive tweets\n",
        "\tprint(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets)))\n",
        "\t# picking negative tweets from tweets\n",
        "\tntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
        "\t# percentage of negative tweets\n",
        "\tprint(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets)))\n",
        "\t# percentage of neutral tweets\n",
        "\tprint(\"Neutral tweets percentage: {} % \\\n",
        "\t\t\".format(100*(len(tweets) -(len( ntweets )+len( ptweets)))/len(tweets)))\n",
        "\n",
        "\t# printing first 5 positive tweets\n",
        "\tprint(\"\\n\\nPositive tweets:\")\n",
        "\tfor tweet in ptweets[:10]:\n",
        "\t\tprint(tweet['text'])\n",
        "\n",
        "\t# printing first 5 negative tweets\n",
        "\tprint(\"\\n\\nNegative tweets:\")\n",
        "\tfor tweet in ntweets[:10]:\n",
        "\t\tprint(tweet['text'])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\t# calling main function\n",
        "\tmain()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edmtFQzfx2Od",
        "outputId": "05edd631-d78a-412c-f57c-973fbc8cc077"
      },
      "source": [
        "!pip install pytrends\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytrends\n",
            "  Downloading pytrends-4.7.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.7/dist-packages (from pytrends) (1.1.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pytrends) (4.2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytrends) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25->pytrends) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytrends) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytrends) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytrends) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytrends) (3.0.4)\n",
            "Installing collected packages: pytrends\n",
            "Successfully installed pytrends-4.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nylS0GA00P5f"
      },
      "source": [
        "\n",
        "from pytrends.request import TrendReq\n",
        "import pandas as pd\n",
        "import time\n",
        "df = pd.read_csv('S&P500-Info.csv')\n",
        "\n",
        "for index, rows in df.iterrows():\n",
        "    kw_list =[rows['Security']] \n",
        "    pytrends.build_payload(kw_list , cat=0, timeframe='today 12-m')\n",
        "    data = pytrends.interest_over_time() \n",
        "    related =pytrends.related_queries()\n",
        "    try:\n",
        "      new_data = related[rows['Security']]['rising'].head(3)\n",
        "      for i,r in new_data.iterrows():\n",
        "        try:\n",
        "          li = [r['query']] \n",
        "          pytrends.build_payload(li , cat=0, timeframe='today 12-m')\n",
        "          re = pytrends.interest_over_time()\n",
        "          data[li[0]] = re[li[0]]\n",
        "        except:\n",
        "          print(\"error\")\n",
        "      try:\n",
        "        data = data.drop('isPartial',1)\n",
        "        data.to_csv(rows['Symbol']+'searchTrend'+'.csv')\n",
        "      except:\n",
        "        print(\"error\")\n",
        "    except:\n",
        "      print(\"error\")\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}